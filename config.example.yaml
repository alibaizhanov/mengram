# Mengram configuration
# Copy to config.yaml and fill in your values

# Path to Obsidian vault (created automatically)
vault_path: "./vault"

# LLM for knowledge extraction from conversations
# Options: anthropic, openai, ollama
llm:
  provider: "anthropic"

  # Anthropic (Claude)
  anthropic:
    api_key: "sk-ant-..."  # your API key
    model: "claude-sonnet-4-20250514"

  # OpenAI
  openai:
    api_key: "sk-..."
    model: "gpt-4o-mini"

  # Ollama (fully local, free)
  ollama:
    base_url: "http://localhost:11434"
    model: "llama3.2"

# Embeddings (for semantic search)
embeddings:
  model: "all-MiniLM-L6-v2"  # local model, 80MB
